{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1OZxnIc_DN2YWS7ZGXcW3NxSDuSiR-Coc",
      "authorship_tag": "ABX9TyN0PoPsUzMVu1RuxoJBw5aX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alianjum520/Ann/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "6u_HJUO4iyRG",
        "outputId": "9fa11aff-bd2c-44d9-f02b-0ba4c9297983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This Section is to read Csv file and store them in an array \n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "path = \"/content/drive/MyDrive/Copy of ass.csv\"\n",
        "path_test = \"/content/drive/MyDrive/Train .csv\"\n",
        "dataset = pd.read_csv(path)\n",
        "dataset_test = pd.read_csv(path_test)\n",
        "dataset = shuffle(dataset)\n",
        "dataset_test = shuffle(dataset_test)\n",
        "\n",
        "x_train = dataset.iloc[:40, 0:5].values\n",
        "y_train = dataset.iloc[:40, 6:].values\n",
        "x_test = dataset_test.iloc[:, 0:5].values\n",
        "y_test = dataset_test.iloc[:, 6:].values\n",
        "\n",
        "x_plot = dataset.iloc[:, 0:1].values\n",
        "x_plot_1 = dataset.iloc[:, 1:2].values\n",
        "x_plot_2 = dataset.iloc[:, 2:3].values\n",
        "x_plot_3 = dataset.iloc[:, 3:4].values\n",
        "x_plot_4 = dataset.iloc[:, 4:5].values\n",
        "'''\n",
        "plot1 = plt.scatter(y_train, x_plot, c=\"r\")\n",
        "\n",
        "plot2 = plt.scatter(y_train, x_plot_1, c=\"g\")\n",
        "\n",
        "\n",
        "plot3 = plt.scatter(y_train,x_plot_2, c=\"b\")\n",
        "plot4 = plt.scatter(y_train, x_plot_3, c= '#FFFF00')\n",
        "plot5 = plt.scatter(y_train,x_plot_4, c = '#000000')'''\n",
        "#x_train = np.array([[[0,0,0,0,0]], [[0,1,0,1,0]], [[1,0,1,0,1]], [[1,1,1,1,0]]])\n",
        "#y_train = np.array([[[0]], [[1]], [[1]], [[0]]])\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=1)\n",
        "y_train = np.expand_dims(y_train, axis=1)\n",
        "x_test = np.expand_dims(x_test, axis=1)\n",
        "print(x_train)\n",
        "print(\"=================================================================\")\n",
        "print(y_train)\n",
        "print(\"=================================================================\")\n",
        "\n",
        "print(x_test)\n",
        "print(\"=================================================================\")\n",
        "\n",
        "print(y_test)\n",
        "print(\"=================================================================\")\n"
      ],
      "metadata": {
        "id": "IOzWbSo6wG41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a87c385-7946-4224-946f-f3aaec871f6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.2  0.25 0.85 1.   1.  ]]\n",
            "\n",
            " [[0.6  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.4  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.6  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 1.   1.  ]]\n",
            "\n",
            " [[0.4  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.4  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.8  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.4  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.6  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.6  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.4  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.6  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.4  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 1.   1.  ]]\n",
            "\n",
            " [[0.6  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.6  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.6  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 1.   1.  ]]\n",
            "\n",
            " [[0.4  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.4  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.6  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.4  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.6  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 0.   1.  ]]\n",
            "\n",
            " [[0.6  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.4  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 0.   1.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 1.   1.  ]]\n",
            "\n",
            " [[0.6  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.6  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 1.   1.  ]]\n",
            "\n",
            " [[0.6  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.4  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.4  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.6  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.6  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.4  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.4  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.4  0.25 0.1  1.   1.  ]]]\n",
            "=================================================================\n",
            "[[[1 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1 0]]\n",
            "\n",
            " [[0 0 1 0 0]]\n",
            "\n",
            " [[0 0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1 0]]\n",
            "\n",
            " [[0 1 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1]]\n",
            "\n",
            " [[0 1 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1]]\n",
            "\n",
            " [[0 0 1 0 0]]\n",
            "\n",
            " [[0 0 0 0 1]]\n",
            "\n",
            " [[0 1 0 0 0]]\n",
            "\n",
            " [[0 0 0 1 0]]\n",
            "\n",
            " [[1 0 0 0 0]]\n",
            "\n",
            " [[0 1 0 0 0]]\n",
            "\n",
            " [[0 0 0 1 0]]\n",
            "\n",
            " [[0 1 0 0 0]]\n",
            "\n",
            " [[1 0 0 0 0]]\n",
            "\n",
            " [[0 1 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1]]\n",
            "\n",
            " [[0 0 0 1 0]]\n",
            "\n",
            " [[0 0 1 0 0]]\n",
            "\n",
            " [[0 0 0 1 0]]\n",
            "\n",
            " [[1 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1]]\n",
            "\n",
            " [[0 0 0 0 1]]\n",
            "\n",
            " [[1 0 0 0 0]]\n",
            "\n",
            " [[1 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 1 0]]\n",
            "\n",
            " [[0 0 1 0 0]]\n",
            "\n",
            " [[1 0 0 0 0]]\n",
            "\n",
            " [[0 0 1 0 0]]\n",
            "\n",
            " [[0 0 1 0 0]]\n",
            "\n",
            " [[0 1 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1]]\n",
            "\n",
            " [[0 0 1 0 0]]\n",
            "\n",
            " [[0 0 0 1 0]]\n",
            "\n",
            " [[0 0 1 0 0]]\n",
            "\n",
            " [[0 1 0 0 0]]]\n",
            "=================================================================\n",
            "[[[0.6  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 1.   1.  ]]\n",
            "\n",
            " [[0.2  0.25 0.85 1.   1.  ]]\n",
            "\n",
            " [[0.6  0.5  0.4  1.   0.  ]]\n",
            "\n",
            " [[0.4  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.4  0.25 0.1  1.   1.  ]]\n",
            "\n",
            " [[0.4  0.9  0.85 1.   1.  ]]\n",
            "\n",
            " [[0.8  0.9  0.1  0.   1.  ]]\n",
            "\n",
            " [[0.4  0.5  0.4  1.   0.  ]]]\n",
            "=================================================================\n",
            "[[0 1 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]]\n",
            "=================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is Section is used to create a layer Class"
      ],
      "metadata": {
        "id": "m8RJ0xnOFKGG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer():\n",
        "    \"\"\"This is the base class for the Layer\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.n_neurons = None\n",
        "  \n",
        "\n",
        "class ConnectedLayer(Layer):\n",
        "  \"\"\"This class is for connectivity of every layer\"\"\"\n",
        "  \n",
        "  def __init__(self, n_inputs, n_neurons):\n",
        "\n",
        "    #initialization of weights\n",
        "    self.weights = np.random.rand(n_inputs, n_neurons) \n",
        "    #in this every neuron will have the same bias  \n",
        "    self.bias = np.random.rand(1, n_neurons) \n",
        "  \n",
        "  #This function is used to calculate forward proagation\n",
        "  def forward_propagation(self,inputs):\n",
        "  \n",
        "    self.input = inputs\n",
        "    self.output = np.dot(self.input, self.weights) + self.bias\n",
        "    return self.output\n",
        "\n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "\n",
        "    input_error = np.dot(output_error, self.weights.T)\n",
        "    weights_error = np.dot(self.input.T, output_error)\n",
        "\n",
        "\n",
        "    # update parameters\n",
        "    self.weights -= learning_rate * weights_error\n",
        "    self.bias -= learning_rate * output_error\n",
        "    return input_error\n",
        "\n",
        "\n",
        "class ActivationLayer(Layer):\n",
        "  \"\"\"This class contains activation function for hidden layers\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, activation, activation_prime):\n",
        "      self.activation = activation\n",
        "      self.activation_prime = activation_prime\n",
        "\n",
        "    # returns the activated input Tanh function used\n",
        "  def forward_propagation(self, inputs):\n",
        "      self.input = inputs\n",
        "      self.output = self.activation(self.input)\n",
        "      return self.output\n",
        "\n",
        "    #Backward propagation used to decrease the errors \n",
        "  def backward_propagation(self, output_error, learning_rate):\n",
        "      return self.activation_prime(self.input) * output_error\n",
        "  \n",
        "  '''def forward_propagation(self, inputs):\n",
        "    \"\"\"In this activation function softmax function is being used\"\"\"\n",
        "    exp_values = np.exp(inputs - np.max(inputs))\n",
        "    probabilities =  exp_values / np.sum(exp_values)\n",
        "    self.output = probabilities '''\n",
        "\n",
        "\n",
        "class Network():\n",
        "    \"\"\"This is the complete Neural Network Class\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.layers = []\n",
        "        self.loss = None\n",
        "        self.loss_prime = None\n",
        "\n",
        "    # add layer to network\n",
        "    def add(self, layer):\n",
        "        self.layers.append(layer)\n",
        "\n",
        "    # set loss to use\n",
        "    def use(self, loss, loss_prime):\n",
        "        self.loss = loss\n",
        "        self.loss_prime = loss_prime\n",
        "\n",
        "    # predict output for given input\n",
        "    def predict(self, input_data):\n",
        "        # sample dimension first\n",
        "        samples = len(input_data)\n",
        "        result = []\n",
        "\n",
        "        # run network over all samples\n",
        "        for i in range(samples):\n",
        "            # forward propagation\n",
        "            output = input_data[i]\n",
        "            for layer in self.layers:\n",
        "                output = layer.forward_propagation(output)\n",
        "            result.append(output)\n",
        "\n",
        "        return result\n",
        "\n",
        "    # train the network\n",
        "    def fit(self, x_train, y_train, epochs, learning_rate):\n",
        "        # sample dimension first\n",
        "        samples = len(x_train)\n",
        "\n",
        "        # training loop\n",
        "        for i in range(epochs):\n",
        "            err = 0\n",
        "            for j in range(samples):\n",
        "                # forward propagation\n",
        "                output = x_train[j]\n",
        "                for layer in self.layers:\n",
        "                    output = layer.forward_propagation(output)\n",
        "\n",
        "                # compute loss (for display purpose only)\n",
        "                err += self.loss(y_train[j], output)\n",
        "\n",
        "                # backward propagation\n",
        "                error = self.loss_prime(y_train[j], output)\n",
        "                for layer in reversed(self.layers):\n",
        "                    error = layer.backward_propagation(error, learning_rate)\n",
        "            # calculate average error on all samples\n",
        "            err /= samples\n",
        "            print('epoch {}/{}   error={}'.format(i+1, epochs, err))\n",
        "\n",
        "# loss function and its derivative\n",
        "def mse(y_true, y_pred):\n",
        "  return np.mean(np.power(y_true-y_pred, 2))\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "  if y_true == 1:\n",
        "    return -np.log(y_pred)\n",
        "  else:\n",
        "    return -np.log(1 - y_pred)\n",
        "\n",
        "#mean sqaured error \n",
        "def mse_prime(y_true, y_pred):\n",
        "  return 2*(y_pred-y_true)/y_true.size\n",
        "\n",
        "# These Functions are used as parameters in Activation Layer\n",
        "'''def tanh(x):\n",
        "  #Apply tan activation function\n",
        "  return np.tanh(x)\n",
        "\n",
        "def tanh_prime(x):\n",
        "  #Gradient of tan \n",
        "  return 1-np.tanh(x)**2'''\n",
        "\n",
        "def sigmoid(x):\n",
        "  #Apply sigmoid activation function\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "  #derivative of sigmoid\n",
        "  x = sigmoid(x)\n",
        "  x = x*(1-x)\n",
        "\n",
        "  return x\n",
        "\n",
        "def accuracy_calculation(actual,predicted):\n",
        "  data = len(actual)\n",
        "  for i in range(data):\n",
        "    accuracy = (predicted[i]/actual[i])*100\n",
        "    print(\"index: {} predicted:{} actual: {} percent: {}\".format(\n",
        "        i, predicted[i], actual[i], accuracy \n",
        "    )\n",
        "    )\n",
        "\n",
        "\n",
        "def get_result(predicted):\n",
        "  results= 0\n",
        "  for i in range(len(predicted)):\n",
        "    position = 0\n",
        "\n",
        "    for j in range(1,len(predicted[i]),1):\n",
        "\n",
        "      if predicted[i][j] > predicted[i][0]:\n",
        "        predicted[i][0] = predicted[i][j]\n",
        "        position = j\n",
        "    '''print(\"The largest value: {} and the position is: {}\".format(\n",
        "        predicted[i][0],\n",
        "        position\n",
        "        ))'''\n",
        "    \n",
        "    if position == 0:\n",
        "      results = 1\n",
        "\n",
        "    elif position == 1:\n",
        "        results = 2\n",
        "\n",
        "    elif position == 2:\n",
        "        results = 3  \n",
        "\n",
        "    elif position == 3:\n",
        "        results = 4\n",
        "\n",
        "    elif position == 4:\n",
        "        results = 5\n",
        "    \n",
        "  \n",
        "  return results\n",
        "\n",
        "# Initialization of different Layer Objects\n",
        "net = Network()\n",
        "net.add(ConnectedLayer(5, 6))\n",
        "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "net.add(ConnectedLayer(6, 5))\n",
        "net.add(ActivationLayer(sigmoid, sigmoid_prime))\n",
        "\n",
        "net.use(mse, mse_prime)\n",
        "x = net.fit(x_train, y_train, epochs=750, learning_rate=0.1)\n",
        "\n",
        "# This is to test the output\n",
        "results = []\n",
        "out = net.predict(x_train)\n",
        "acc = accuracy_calculation(y_train,out)\n",
        "for i in range(len(out)):\n",
        "  data = get_result(out[i])\n",
        "  results.append(data)\n",
        "print(\"The Calculated Results of the training dataset are: {}\".format(\n",
        "    results\n",
        "    ))\n",
        " \n",
        "\n",
        "#Test Output\n",
        "print(\"======================TESTING DATA OUTPUT=============================\")\n",
        "#OKAY SOO WE ARE FACING THE ERROR THAT OUR DATA IS NOT RANDOMISED OF OUTPUTS IT\n",
        "#IS IN COMPLETE SEQUENCE SO WHENEVER THE MODEL PREDICTS IT SHOWS THE SEQUENCE\n",
        "out2 = net.predict(x_test)\n",
        "#acc2 = accuracy_calculation(y_test,out)\n",
        "predicted_results =[]\n",
        "\n",
        "for i in range(len(out2)):\n",
        "  data = get_result(out2[i])\n",
        "  predicted_results.append(data)\n",
        "\n",
        "print(\"The Predicted Results of the testing dataset are: {}\".format(\n",
        "    predicted_results\n",
        "    ))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oz5i6LHeFBbl",
        "outputId": "be075e8c-9d83-415f-ddcb-bf51859e10b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1/750   error=0.6336096732507406\n",
            "epoch 2/750   error=0.5342481429289417\n",
            "epoch 3/750   error=0.413887115700874\n",
            "epoch 4/750   error=0.30997686915390243\n",
            "epoch 5/750   error=0.23559482042268645\n",
            "epoch 6/750   error=0.19170551942011188\n",
            "epoch 7/750   error=0.17327601200555526\n",
            "epoch 8/750   error=0.16618160821779354\n",
            "epoch 9/750   error=0.16308558221895214\n",
            "epoch 10/750   error=0.16154773578999165\n",
            "epoch 11/750   error=0.1607043420736469\n",
            "epoch 12/750   error=0.1602036790271904\n",
            "epoch 13/750   error=0.1598849267489461\n",
            "epoch 14/750   error=0.1596679039452207\n",
            "epoch 15/750   error=0.1595099665832313\n",
            "epoch 16/750   error=0.15938729446062846\n",
            "epoch 17/750   error=0.15928606622942693\n",
            "epoch 18/750   error=0.15919801669551592\n",
            "epoch 19/750   error=0.15911808047237802\n",
            "epoch 20/750   error=0.15904308849461385\n",
            "epoch 21/750   error=0.15897102185394302\n",
            "epoch 22/750   error=0.15890057253642237\n",
            "epoch 23/750   error=0.1588308788011949\n",
            "epoch 24/750   error=0.15876136269640018\n",
            "epoch 25/750   error=0.15869162869072628\n",
            "epoch 26/750   error=0.1586213995812702\n",
            "epoch 27/750   error=0.15855047550517481\n",
            "epoch 28/750   error=0.1584787074655505\n",
            "epoch 29/750   error=0.15840598008028875\n",
            "epoch 30/750   error=0.1583322002488204\n",
            "epoch 31/750   error=0.15825728964832167\n",
            "epoch 32/750   error=0.15818117972642357\n",
            "epoch 33/750   error=0.1581038083324468\n",
            "epoch 34/750   error=0.15802511743084538\n",
            "epoch 35/750   error=0.1579450515338099\n",
            "epoch 36/750   error=0.15786355661473755\n",
            "epoch 37/750   error=0.15778057934532758\n",
            "epoch 38/750   error=0.15769606655201798\n",
            "epoch 39/750   error=0.15760996482226117\n",
            "epoch 40/750   error=0.15752222021408602\n",
            "epoch 41/750   error=0.15743277803760553\n",
            "epoch 42/750   error=0.15734158268726253\n",
            "epoch 43/750   error=0.1572485775103811\n",
            "epoch 44/750   error=0.1571537047021509\n",
            "epoch 45/750   error=0.15705690522025462\n",
            "epoch 46/750   error=0.15695811871444712\n",
            "epoch 47/750   error=0.15685728346783395\n",
            "epoch 48/750   error=0.15675433634759353\n",
            "epoch 49/750   error=0.15664921276358032\n",
            "epoch 50/750   error=0.15654184663374107\n",
            "epoch 51/750   error=0.15643217035562296\n",
            "epoch 52/750   error=0.1563201147835109\n",
            "epoch 53/750   error=0.1562056092109136\n",
            "epoch 54/750   error=0.15608858135825895\n",
            "epoch 55/750   error=0.15596895736576324\n",
            "epoch 56/750   error=0.15584666179151388\n",
            "epoch 57/750   error=0.15572161761486755\n",
            "epoch 58/750   error=0.15559374624530692\n",
            "epoch 59/750   error=0.15546296753693156\n",
            "epoch 60/750   error=0.15532919980878093\n",
            "epoch 61/750   error=0.1551923598711964\n",
            "epoch 62/750   error=0.15505236305843836\n",
            "epoch 63/750   error=0.1549091232677679\n",
            "epoch 64/750   error=0.1547625530051941\n",
            "epoch 65/750   error=0.1546125634380729\n",
            "epoch 66/750   error=0.1544590644547169\n",
            "epoch 67/750   error=0.15430196473115348\n",
            "epoch 68/750   error=0.15414117180512565\n",
            "epoch 69/750   error=0.15397659215739828\n",
            "epoch 70/750   error=0.15380813130038165\n",
            "epoch 71/750   error=0.15363569387403891\n",
            "epoch 72/750   error=0.15345918374898768\n",
            "epoch 73/750   error=0.1532785041366547\n",
            "epoch 74/750   error=0.1530935577062791\n",
            "epoch 75/750   error=0.1529042467085077\n",
            "epoch 76/750   error=0.15271047310526084\n",
            "epoch 77/750   error=0.1525121387054985\n",
            "epoch 78/750   error=0.15230914530645642\n",
            "epoch 79/750   error=0.15210139483987956\n",
            "epoch 80/750   error=0.1518887895227354\n",
            "epoch 81/750   error=0.15167123201185811\n",
            "epoch 82/750   error=0.15144862556194932\n",
            "epoch 83/750   error=0.15122087418634894\n",
            "epoch 84/750   error=0.1509878828199894\n",
            "epoch 85/750   error=0.15074955748395774\n",
            "epoch 86/750   error=0.15050580545111633\n",
            "epoch 87/750   error=0.15025653541227377\n",
            "epoch 88/750   error=0.1500016576424499\n",
            "epoch 89/750   error=0.14974108416684767\n",
            "epoch 90/750   error=0.14947472892622155\n",
            "epoch 91/750   error=0.14920250794142462\n",
            "epoch 92/750   error=0.1489243394770123\n",
            "epoch 93/750   error=0.1486401442038882\n",
            "epoch 94/750   error=0.14834984536108287\n",
            "epoch 95/750   error=0.148053368916869\n",
            "epoch 96/750   error=0.14775064372951907\n",
            "epoch 97/750   error=0.14744160170811466\n",
            "epoch 98/750   error=0.14712617797390648\n",
            "epoch 99/750   error=0.14680431102280372\n",
            "epoch 100/750   error=0.14647594288963564\n",
            "epoch 101/750   error=0.14614101931487364\n",
            "epoch 102/750   error=0.14579948991452946\n",
            "epoch 103/750   error=0.14545130835395004\n",
            "epoch 104/750   error=0.14509643252621218\n",
            "epoch 105/750   error=0.14473482473577945\n",
            "epoch 106/750   error=0.14436645188801978\n",
            "epoch 107/750   error=0.14399128568509512\n",
            "epoch 108/750   error=0.14360930282862508\n",
            "epoch 109/750   error=0.14322048522939435\n",
            "epoch 110/750   error=0.14282482022422266\n",
            "epoch 111/750   error=0.1424223007999441\n",
            "epoch 112/750   error=0.14201292582425512\n",
            "epoch 113/750   error=0.14159670028298138\n",
            "epoch 114/750   error=0.1411736355230967\n",
            "epoch 115/750   error=0.14074374950058582\n",
            "epoch 116/750   error=0.14030706703199902\n",
            "epoch 117/750   error=0.1398636200482806\n",
            "epoch 118/750   error=0.13941344784918464\n",
            "epoch 119/750   error=0.13895659735630758\n",
            "epoch 120/750   error=0.13849312336248135\n",
            "epoch 121/750   error=0.1380230887749761\n",
            "epoch 122/750   error=0.13754656484967231\n",
            "epoch 123/750   error=0.13706363141307104\n",
            "epoch 124/750   error=0.13657437706873507\n",
            "epoch 125/750   error=0.1360788993844944\n",
            "epoch 126/750   error=0.1355773050565151\n",
            "epoch 127/750   error=0.13506971004613594\n",
            "epoch 128/750   error=0.134556239685227\n",
            "epoch 129/750   error=0.13403702874573759\n",
            "epoch 130/750   error=0.13351222146908365\n",
            "epoch 131/750   error=0.13298197155109623\n",
            "epoch 132/750   error=0.13244644207841658\n",
            "epoch 133/750   error=0.1319058054124996\n",
            "epoch 134/750   error=0.13136024301777555\n",
            "epoch 135/750   error=0.13080994523102984\n",
            "epoch 136/750   error=0.13025511096969242\n",
            "epoch 137/750   error=0.1296959473774763\n",
            "epoch 138/750   error=0.1291326694066644\n",
            "epoch 139/750   error=0.12856549933729566\n",
            "epoch 140/750   error=0.1279946662345308\n",
            "epoch 141/750   error=0.12742040534655827\n",
            "epoch 142/750   error=0.1268429574465015\n",
            "epoch 143/750   error=0.12626256812288125\n",
            "epoch 144/750   error=0.12567948702423132\n",
            "epoch 145/750   error=0.12509396706443593\n",
            "epoch 146/750   error=0.12450626359620756\n",
            "epoch 147/750   error=0.12391663356083409\n",
            "epoch 148/750   error=0.12332533462286425\n",
            "epoch 149/750   error=0.12273262429874714\n",
            "epoch 150/750   error=0.12213875908858507\n",
            "epoch 151/750   error=0.12154399362009574\n",
            "epoch 152/750   error=0.12094857981360776\n",
            "epoch 153/750   error=0.12035276607644589\n",
            "epoch 154/750   error=0.11975679653442006\n",
            "epoch 155/750   error=0.11916091030733336\n",
            "epoch 156/750   error=0.11856534083450396\n",
            "epoch 157/750   error=0.11797031525528434\n",
            "epoch 158/750   error=0.11737605384848981\n",
            "epoch 159/750   error=0.11678276953355712\n",
            "epoch 160/750   error=0.11619066743517052\n",
            "epoch 161/750   error=0.11559994451204858\n",
            "epoch 162/750   error=0.11501078924960498\n",
            "epoch 163/750   error=0.1144233814153051\n",
            "epoch 164/750   error=0.11383789187474727\n",
            "epoch 165/750   error=0.11325448246582015\n",
            "epoch 166/750   error=0.11267330592772724\n",
            "epoch 167/750   error=0.11209450588122964\n",
            "epoch 168/750   error=0.11151821685613512\n",
            "epoch 169/750   error=0.11094456436184859\n",
            "epoch 170/750   error=0.1103736649966878\n",
            "epoch 171/750   error=0.10980562659164914\n",
            "epoch 172/750   error=0.10924054838436528\n",
            "epoch 173/750   error=0.10867852121912287\n",
            "epoch 174/750   error=0.1081196277689865\n",
            "epoch 175/750   error=0.10756394277629437\n",
            "epoch 176/750   error=0.10701153330804355\n",
            "epoch 177/750   error=0.10646245902295012\n",
            "epoch 178/750   error=0.10591677244725348\n",
            "epoch 179/750   error=0.10537451925661659\n",
            "epoch 180/750   error=0.10483573856175563\n",
            "epoch 181/750   error=0.10430046319570718\n",
            "epoch 182/750   error=0.1037687200008979\n",
            "epoch 183/750   error=0.10324053011443073\n",
            "epoch 184/750   error=0.10271590925022807\n",
            "epoch 185/750   error=0.10219486797688208\n",
            "epoch 186/750   error=0.10167741199025433\n",
            "epoch 187/750   error=0.10116354238003786\n",
            "epoch 188/750   error=0.10065325588965132\n",
            "epoch 189/750   error=0.10014654516896877\n",
            "epoch 190/750   error=0.09964339901951097\n",
            "epoch 191/750   error=0.09914380263182933\n",
            "epoch 192/750   error=0.09864773781490359\n",
            "epoch 193/750   error=0.0981551832174545\n",
            "epoch 194/750   error=0.09766611454113949\n",
            "epoch 195/750   error=0.09718050474565593\n",
            "epoch 196/750   error=0.09669832424582683\n",
            "epoch 197/750   error=0.09621954110078206\n",
            "epoch 198/750   error=0.09574412119538195\n",
            "epoch 199/750   error=0.09527202841405992\n",
            "epoch 200/750   error=0.09480322480727923\n",
            "epoch 201/750   error=0.09433767075081986\n",
            "epoch 202/750   error=0.0938753250981232\n",
            "epoch 203/750   error=0.09341614532593363\n",
            "epoch 204/750   error=0.09296008767348277\n",
            "epoch 205/750   error=0.09250710727546793\n",
            "epoch 206/750   error=0.09205715828907743\n",
            "epoch 207/750   error=0.09161019401531788\n",
            "epoch 208/750   error=0.09116616701489638\n",
            "epoch 209/750   error=0.0907250292189086\n",
            "epoch 210/750   error=0.09028673203458012\n",
            "epoch 211/750   error=0.0898512264463033\n",
            "epoch 212/750   error=0.08941846311220661\n",
            "epoch 213/750   error=0.08898839245648592\n",
            "epoch 214/750   error=0.08856096475772098\n",
            "epoch 215/750   error=0.08813613023339065\n",
            "epoch 216/750   error=0.08771383912079321\n",
            "epoch 217/750   error=0.08729404175456765\n",
            "epoch 218/750   error=0.08687668864100277\n",
            "epoch 219/750   error=0.08646173052931046\n",
            "epoch 220/750   error=0.08604911848002923\n",
            "epoch 221/750   error=0.08563880393071341\n",
            "epoch 222/750   error=0.08523073875905164\n",
            "epoch 223/750   error=0.08482487534354859\n",
            "epoch 224/750   error=0.08442116662189118\n",
            "epoch 225/750   error=0.08401956614710995\n",
            "epoch 226/750   error=0.08362002814163513\n",
            "epoch 227/750   error=0.08322250754933448\n",
            "epoch 228/750   error=0.08282696008561038\n",
            "epoch 229/750   error=0.08243334228562163\n",
            "epoch 230/750   error=0.08204161155068411\n",
            "epoch 231/750   error=0.08165172619289504\n",
            "epoch 232/750   error=0.0812636454780144\n",
            "epoch 233/750   error=0.08087732966662674\n",
            "epoch 234/750   error=0.08049274005359798\n",
            "epoch 235/750   error=0.08010983900583159\n",
            "epoch 236/750   error=0.07972858999832039\n",
            "epoch 237/750   error=0.0793489576484809\n",
            "epoch 238/750   error=0.07897090774875129\n",
            "epoch 239/750   error=0.07859440729742459\n",
            "epoch 240/750   error=0.07821942452768418\n",
            "epoch 241/750   error=0.07784592893480093\n",
            "epoch 242/750   error=0.07747389130144793\n",
            "epoch 243/750   error=0.07710328372108267\n",
            "epoch 244/750   error=0.07673407961934374\n",
            "epoch 245/750   error=0.07636625377340557\n",
            "epoch 246/750   error=0.07599978232923299\n",
            "epoch 247/750   error=0.07563464281667538\n",
            "epoch 248/750   error=0.07527081416234019\n",
            "epoch 249/750   error=0.07490827670018561\n",
            "epoch 250/750   error=0.07454701217977269\n",
            "epoch 251/750   error=0.07418700377212037\n",
            "epoch 252/750   error=0.07382823607310807\n",
            "epoch 253/750   error=0.07347069510437568\n",
            "epoch 254/750   error=0.07311436831167348\n",
            "epoch 255/750   error=0.07275924456062108\n",
            "epoch 256/750   error=0.07240531412983937\n",
            "epoch 257/750   error=0.07205256870142698\n",
            "epoch 258/750   error=0.07170100134875879\n",
            "epoch 259/750   error=0.07135060652159375\n",
            "epoch 260/750   error=0.07100138002848577\n",
            "epoch 261/750   error=0.07065331901650215\n",
            "epoch 262/750   error=0.07030642194826314\n",
            "epoch 263/750   error=0.06996068857632472\n",
            "epoch 264/750   error=0.06961611991493952\n",
            "epoch 265/750   error=0.06927271820923894\n",
            "epoch 266/750   error=0.06893048690189177\n",
            "epoch 267/750   error=0.06858943059730362\n",
            "epoch 268/750   error=0.06824955502343485\n",
            "epoch 269/750   error=0.06791086699132254\n",
            "epoch 270/750   error=0.06757337435240396\n",
            "epoch 271/750   error=0.06723708595374961\n",
            "epoch 272/750   error=0.06690201159132232\n",
            "epoch 273/750   error=0.06656816196138955\n",
            "epoch 274/750   error=0.06623554861022432\n",
            "epoch 275/750   error=0.06590418388223898\n",
            "epoch 276/750   error=0.06557408086670245\n",
            "epoch 277/750   error=0.06524525334320061\n",
            "epoch 278/750   error=0.064917715726003\n",
            "epoch 279/750   error=0.0645914830075062\n",
            "epoch 280/750   error=0.06426657070092796\n",
            "epoch 281/750   error=0.06394299478242872\n",
            "epoch 282/750   error=0.06362077163284116\n",
            "epoch 283/750   error=0.06329991797918821\n",
            "epoch 284/750   error=0.06298045083617118\n",
            "epoch 285/750   error=0.06266238744780936\n",
            "epoch 286/750   error=0.062345745229409597\n",
            "epoch 287/750   error=0.06203054171004313\n",
            "epoch 288/750   error=0.061716794475702365\n",
            "epoch 289/750   error=0.0614045211133061\n",
            "epoch 290/750   error=0.06109373915571668\n",
            "epoch 291/750   error=0.06078446602792529\n",
            "epoch 292/750   error=0.06047671899455585\n",
            "epoch 293/750   error=0.06017051510882889\n",
            "epoch 294/750   error=0.059865871163119345\n",
            "epoch 295/750   error=0.05956280364123253\n",
            "epoch 296/750   error=0.059261328672514005\n",
            "epoch 297/750   error=0.0589614619878967\n",
            "epoch 298/750   error=0.05866321887798207\n",
            "epoch 299/750   error=0.05836661415323754\n",
            "epoch 300/750   error=0.058071662106384425\n",
            "epoch 301/750   error=0.057778376477038595\n",
            "epoch 302/750   error=0.057486770418654964\n",
            "epoch 303/750   error=0.0571968564678164\n",
            "epoch 304/750   error=0.05690864651589683\n",
            "epoch 305/750   error=0.05662215178311789\n",
            "epoch 306/750   error=0.056337382795007204\n",
            "epoch 307/750   error=0.05605434936125793\n",
            "epoch 308/750   error=0.05577306055697782\n",
            "epoch 309/750   error=0.05549352470630845\n",
            "epoch 310/750   error=0.055215749368385005\n",
            "epoch 311/750   error=0.054939741325600054\n",
            "epoch 312/750   error=0.054665506574126055\n",
            "epoch 313/750   error=0.05439305031664472\n",
            "epoch 314/750   error=0.05412237695722476\n",
            "epoch 315/750   error=0.05385349009828294\n",
            "epoch 316/750   error=0.05358639253955931\n",
            "epoch 317/750   error=0.05332108627903094\n",
            "epoch 318/750   error=0.05305757251568621\n",
            "epoch 319/750   error=0.05279585165407678\n",
            "epoch 320/750   error=0.05253592331056184\n",
            "epoch 321/750   error=0.052277786321157385\n",
            "epoch 322/750   error=0.052021438750900525\n",
            "epoch 323/750   error=0.0517668779046383\n",
            "epoch 324/750   error=0.051514100339149646\n",
            "epoch 325/750   error=0.051263101876508156\n",
            "epoch 326/750   error=0.051013877618594515\n",
            "epoch 327/750   error=0.05076642196266763\n",
            "epoch 328/750   error=0.050520728617903944\n",
            "epoch 329/750   error=0.05027679062281689\n",
            "epoch 330/750   error=0.05003460036346937\n",
            "epoch 331/750   error=0.049794149592394255\n",
            "epoch 332/750   error=0.04955542944814046\n",
            "epoch 333/750   error=0.0493184304753644\n",
            "epoch 334/750   error=0.04908314264538953\n",
            "epoch 335/750   error=0.04884955537715928\n",
            "epoch 336/750   error=0.04861765755851206\n",
            "epoch 337/750   error=0.04838743756770999\n",
            "epoch 338/750   error=0.04815888329515618\n",
            "epoch 339/750   error=0.047931982165238855\n",
            "epoch 340/750   error=0.047706721158243856\n",
            "epoch 341/750   error=0.04748308683228029\n",
            "epoch 342/750   error=0.047261065345167885\n",
            "epoch 343/750   error=0.047040642476237224\n",
            "epoch 344/750   error=0.046821803647998414\n",
            "epoch 345/750   error=0.04660453394763564\n",
            "epoch 346/750   error=0.04638881814828937\n",
            "epoch 347/750   error=0.04617464073009083\n",
            "epoch 348/750   error=0.04596198590091577\n",
            "epoch 349/750   error=0.045750837616828376\n",
            "epoch 350/750   error=0.04554117960218841\n",
            "epoch 351/750   error=0.045332995369397625\n",
            "epoch 352/750   error=0.04512626823826397\n",
            "epoch 353/750   error=0.04492098135496469\n",
            "epoch 354/750   error=0.04471711771059197\n",
            "epoch 355/750   error=0.04451466015926646\n",
            "epoch 356/750   error=0.044313591435806904\n",
            "epoch 357/750   error=0.0441138941729453\n",
            "epoch 358/750   error=0.043915550918079756\n",
            "epoch 359/750   error=0.043718544149558204\n",
            "epoch 360/750   error=0.043522856292488116\n",
            "epoch 361/750   error=0.043328469734069036\n",
            "epoch 362/750   error=0.04313536683844592\n",
            "epoch 363/750   error=0.0429435299610826\n",
            "epoch 364/750   error=0.042752941462655986\n",
            "epoch 365/750   error=0.04256358372247282\n",
            "epoch 366/750   error=0.04237543915141137\n",
            "epoch 367/750   error=0.042188490204392005\n",
            "epoch 368/750   error=0.04200271939238069\n",
            "epoch 369/750   error=0.041818109293930955\n",
            "epoch 370/750   error=0.04163464256626964\n",
            "epoch 371/750   error=0.04145230195593342\n",
            "epoch 372/750   error=0.041271070308962196\n",
            "epoch 373/750   error=0.04109093058065759\n",
            "epoch 374/750   error=0.04091186584491344\n",
            "epoch 375/750   error=0.04073385930312674\n",
            "epoch 376/750   error=0.040556894292697376\n",
            "epoch 377/750   error=0.04038095429512479\n",
            "epoch 378/750   error=0.040206022943710645\n",
            "epoch 379/750   error=0.04003208403087609\n",
            "epoch 380/750   error=0.039859121515102576\n",
            "epoch 381/750   error=0.039687119527505026\n",
            "epoch 382/750   error=0.03951606237804657\n",
            "epoch 383/750   error=0.03934593456140366\n",
            "epoch 384/750   error=0.039176720762490416\n",
            "epoch 385/750   error=0.039008405861651226\n",
            "epoch 386/750   error=0.038840974939530364\n",
            "epoch 387/750   error=0.03867441328162714\n",
            "epoch 388/750   error=0.0385087063825454\n",
            "epoch 389/750   error=0.038343839949945654\n",
            "epoch 390/750   error=0.038179799908208134\n",
            "epoch 391/750   error=0.0380165724018153\n",
            "epoch 392/750   error=0.037854143798461165\n",
            "epoch 393/750   error=0.03769250069189588\n",
            "epoch 394/750   error=0.03753162990451302\n",
            "epoch 395/750   error=0.037371518489687075\n",
            "epoch 396/750   error=0.037212153733868374\n",
            "epoch 397/750   error=0.03705352315844301\n",
            "epoch 398/750   error=0.03689561452136425\n",
            "epoch 399/750   error=0.03673841581856273\n",
            "epoch 400/750   error=0.03658191528514157\n",
            "epoch 401/750   error=0.03642610139636344\n",
            "epoch 402/750   error=0.03627096286843541\n",
            "epoch 403/750   error=0.03611648865909814\n",
            "epoch 404/750   error=0.03596266796802494\n",
            "epoch 405/750   error=0.03580949023703717\n",
            "epoch 406/750   error=0.03565694515014094\n",
            "epoch 407/750   error=0.03550502263339121\n",
            "epoch 408/750   error=0.03535371285458853\n",
            "epoch 409/750   error=0.035203006222813554\n",
            "epoch 410/750   error=0.03505289338780462\n",
            "epoch 411/750   error=0.034903365239183345\n",
            "epoch 412/750   error=0.03475441290553331\n",
            "epoch 413/750   error=0.03460602775333628\n",
            "epoch 414/750   error=0.034458201385771006\n",
            "epoch 415/750   error=0.03431092564137895\n",
            "epoch 416/750   error=0.03416419259260159\n",
            "epoch 417/750   error=0.034017994544193526\n",
            "epoch 418/750   error=0.033872324031515993\n",
            "epoch 419/750   error=0.03372717381871456\n",
            "epoch 420/750   error=0.03358253689678577\n",
            "epoch 421/750   error=0.03343840648153619\n",
            "epoch 422/750   error=0.0332947760114385\n",
            "epoch 423/750   error=0.033151639145388094\n",
            "epoch 424/750   error=0.03300898976036435\n",
            "epoch 425/750   error=0.032866821949000424\n",
            "epoch 426/750   error=0.032725130017065285\n",
            "epoch 427/750   error=0.03258390848086181\n",
            "epoch 428/750   error=0.032443152064544574\n",
            "epoch 429/750   error=0.032302855697361105\n",
            "epoch 430/750   error=0.03216301451082018\n",
            "epoch 431/750   error=0.03202362383579071\n",
            "epoch 432/750   error=0.031884679199534784\n",
            "epoch 433/750   error=0.03174617632267858\n",
            "epoch 434/750   error=0.03160811111612417\n",
            "epoch 435/750   error=0.03147047967790618\n",
            "epoch 436/750   error=0.03133327828999642\n",
            "epoch 437/750   error=0.031196503415059952\n",
            "epoch 438/750   error=0.03106015169316586\n",
            "epoch 439/750   error=0.030924219938456177\n",
            "epoch 440/750   error=0.03078870513577628\n",
            "epoch 441/750   error=0.030653604437269714\n",
            "epoch 442/750   error=0.0305189151589411\n",
            "epoch 443/750   error=0.03038463477718979\n",
            "epoch 444/750   error=0.030250760925318126\n",
            "epoch 445/750   error=0.030117291390016575\n",
            "epoch 446/750   error=0.029984224107829534\n",
            "epoch 447/750   error=0.029851557161604363\n",
            "epoch 448/750   error=0.029719288776927043\n",
            "epoch 449/750   error=0.02958741731854696\n",
            "epoch 450/750   error=0.02945594128679413\n",
            "epoch 451/750   error=0.02932485931399148\n",
            "epoch 452/750   error=0.029194170160865163\n",
            "epoch 453/750   error=0.029063872712955473\n",
            "epoch 454/750   error=0.02893396597703137\n",
            "epoch 455/750   error=0.02880444907751094\n",
            "epoch 456/750   error=0.02867532125289064\n",
            "epoch 457/750   error=0.02854658185218583\n",
            "epoch 458/750   error=0.028418230331385037\n",
            "epoch 459/750   error=0.02829026624992039\n",
            "epoch 460/750   error=0.028162689267156676\n",
            "epoch 461/750   error=0.02803549913890111\n",
            "epoch 462/750   error=0.02790869571393646\n",
            "epoch 463/750   error=0.027782278930579208\n",
            "epoch 464/750   error=0.0276562488132653\n",
            "epoch 465/750   error=0.027530605469165137\n",
            "epoch 466/750   error=0.027405349084830118\n",
            "epoch 467/750   error=0.027280479922872358\n",
            "epoch 468/750   error=0.027155998318679604\n",
            "epoch 469/750   error=0.027031904677166835\n",
            "epoch 470/750   error=0.02690819946956658\n",
            "epoch 471/750   error=0.026784883230259272\n",
            "epoch 472/750   error=0.026661956553645127\n",
            "epoch 473/750   error=0.026539420091059196\n",
            "epoch 474/750   error=0.02641727454773094\n",
            "epoch 475/750   error=0.026295520679789304\n",
            "epoch 476/750   error=0.02617415929131487\n",
            "epoch 477/750   error=0.026053191231440086\n",
            "epoch 478/750   error=0.025932617391498557\n",
            "epoch 479/750   error=0.025812438702224418\n",
            "epoch 480/750   error=0.025692656131002772\n",
            "epoch 481/750   error=0.02557327067917186\n",
            "epoch 482/750   error=0.025454283379378034\n",
            "epoch 483/750   error=0.025335695292983563\n",
            "epoch 484/750   error=0.025217507507528825\n",
            "epoch 485/750   error=0.025099721134248458\n",
            "epoch 486/750   error=0.02498233730564265\n",
            "epoch 487/750   error=0.024865357173103543\n",
            "epoch 488/750   error=0.024748781904597266\n",
            "epoch 489/750   error=0.024632612682401793\n",
            "epoch 490/750   error=0.024516850700900907\n",
            "epoch 491/750   error=0.024401497164434228\n",
            "epoch 492/750   error=0.024286553285203488\n",
            "epoch 493/750   error=0.02417202028123516\n",
            "epoch 494/750   error=0.024057899374399214\n",
            "epoch 495/750   error=0.023944191788483955\n",
            "epoch 496/750   error=0.02383089874732679\n",
            "epoch 497/750   error=0.023718021473000846\n",
            "epoch 498/750   error=0.02360556118405697\n",
            "epoch 499/750   error=0.023493519093820768\n",
            "epoch 500/750   error=0.023381896408744798\n",
            "epoch 501/750   error=0.02327069432681478\n",
            "epoch 502/750   error=0.02315991403601009\n",
            "epoch 503/750   error=0.023049556712817568\n",
            "epoch 504/750   error=0.022939623520798435\n",
            "epoch 505/750   error=0.02283011560920744\n",
            "epoch 506/750   error=0.022721034111664127\n",
            "epoch 507/750   error=0.02261238014487511\n",
            "epoch 508/750   error=0.02250415480740698\n",
            "epoch 509/750   error=0.022396359178509136\n",
            "epoch 510/750   error=0.022288994316985875\n",
            "epoch 511/750   error=0.02218206126011685\n",
            "epoch 512/750   error=0.022075561022625277\n",
            "epoch 513/750   error=0.021969494595693282\n",
            "epoch 514/750   error=0.02186386294602317\n",
            "epoch 515/750   error=0.02175866701494431\n",
            "epoch 516/750   error=0.0216539077175645\n",
            "epoch 517/750   error=0.021549585941965044\n",
            "epoch 518/750   error=0.021445702548438868\n",
            "epoch 519/750   error=0.021342258368770524\n",
            "epoch 520/750   error=0.021239254205557584\n",
            "epoch 521/750   error=0.021136690831572234\n",
            "epoch 522/750   error=0.021034568989162485\n",
            "epoch 523/750   error=0.020932889389691792\n",
            "epoch 524/750   error=0.020831652713016704\n",
            "epoch 525/750   error=0.020730859607001034\n",
            "epoch 526/750   error=0.020630510687066263\n",
            "epoch 527/750   error=0.02053060653577694\n",
            "epoch 528/750   error=0.020431147702460347\n",
            "epoch 529/750   error=0.020332134702859505\n",
            "epoch 530/750   error=0.020233568018818666\n",
            "epoch 531/750   error=0.020135448098000504\n",
            "epoch 532/750   error=0.02003777535363399\n",
            "epoch 533/750   error=0.01994055016429231\n",
            "epoch 534/750   error=0.019843772873699688\n",
            "epoch 535/750   error=0.019747443790566692\n",
            "epoch 536/750   error=0.01965156318845276\n",
            "epoch 537/750   error=0.019556131305655453\n",
            "epoch 538/750   error=0.019461148345125398\n",
            "epoch 539/750   error=0.01936661447440638\n",
            "epoch 540/750   error=0.01927252982559948\n",
            "epoch 541/750   error=0.019178894495350787\n",
            "epoch 542/750   error=0.0190857085448616\n",
            "epoch 543/750   error=0.018992971999920803\n",
            "epoch 544/750   error=0.01890068485095816\n",
            "epoch 545/750   error=0.018808847053118156\n",
            "epoch 546/750   error=0.018717458526353623\n",
            "epoch 547/750   error=0.01862651915553825\n",
            "epoch 548/750   error=0.018536028790597504\n",
            "epoch 549/750   error=0.018445987246657206\n",
            "epoch 550/750   error=0.01835639430420905\n",
            "epoch 551/750   error=0.018267249709292426\n",
            "epoch 552/750   error=0.018178553173692\n",
            "epoch 553/750   error=0.018090304375150267\n",
            "epoch 554/750   error=0.01800250295759466\n",
            "epoch 555/750   error=0.017915148531378315\n",
            "epoch 556/750   error=0.017828240673534383\n",
            "epoch 557/750   error=0.017741778928042618\n",
            "epoch 558/750   error=0.01765576280610852\n",
            "epoch 559/750   error=0.017570191786453703\n",
            "epoch 560/750   error=0.017485065315617502\n",
            "epoch 561/750   error=0.017400382808268937\n",
            "epoch 562/750   error=0.01731614364752882\n",
            "epoch 563/750   error=0.017232347185301262\n",
            "epoch 564/750   error=0.01714899274261418\n",
            "epoch 565/750   error=0.01706607960996847\n",
            "epoch 566/750   error=0.01698360704769509\n",
            "epoch 567/750   error=0.01690157428631988\n",
            "epoch 568/750   error=0.01681998052693552\n",
            "epoch 569/750   error=0.016738824941580292\n",
            "epoch 570/750   error=0.01665810667362313\n",
            "epoch 571/750   error=0.016577824838154693\n",
            "epoch 572/750   error=0.016497978522383806\n",
            "epoch 573/750   error=0.016418566786039347\n",
            "epoch 574/750   error=0.016339588661776712\n",
            "epoch 575/750   error=0.016261043155588698\n",
            "epoch 576/750   error=0.016182929247220677\n",
            "epoch 577/750   error=0.01610524589058921\n",
            "epoch 578/750   error=0.016027992014204333\n",
            "epoch 579/750   error=0.015951166521594822\n",
            "epoch 580/750   error=0.015874768291736112\n",
            "epoch 581/750   error=0.015798796179480955\n",
            "epoch 582/750   error=0.015723249015991952\n",
            "epoch 583/750   error=0.015648125609176198\n",
            "epoch 584/750   error=0.015573424744121447\n",
            "epoch 585/750   error=0.015499145183533606\n",
            "epoch 586/750   error=0.015425285668175342\n",
            "epoch 587/750   error=0.015351844917305527\n",
            "epoch 588/750   error=0.01527882162911926\n",
            "epoch 589/750   error=0.0152062144811882\n",
            "epoch 590/750   error=0.01513402213090112\n",
            "epoch 591/750   error=0.015062243215904266\n",
            "epoch 592/750   error=0.014990876354541462\n",
            "epoch 593/750   error=0.014919920146293637\n",
            "epoch 594/750   error=0.014849373172217763\n",
            "epoch 595/750   error=0.014779233995384672\n",
            "epoch 596/750   error=0.014709501161315992\n",
            "epoch 597/750   error=0.014640173198419695\n",
            "epoch 598/750   error=0.01457124861842416\n",
            "epoch 599/750   error=0.014502725916810691\n",
            "epoch 600/750   error=0.014434603573244284\n",
            "epoch 601/750   error=0.014366880052002293\n",
            "epoch 602/750   error=0.01429955380240123\n",
            "epoch 603/750   error=0.014232623259221172\n",
            "epoch 604/750   error=0.014166086843127836\n",
            "epoch 605/750   error=0.014099942961092248\n",
            "epoch 606/750   error=0.01403419000680759\n",
            "epoch 607/750   error=0.013968826361103515\n",
            "epoch 608/750   error=0.013903850392357425\n",
            "epoch 609/750   error=0.013839260456902858\n",
            "epoch 610/750   error=0.013775054899434707\n",
            "epoch 611/750   error=0.013711232053411338\n",
            "epoch 612/750   error=0.013647790241453291\n",
            "epoch 613/750   error=0.01358472777573875\n",
            "epoch 614/750   error=0.01352204295839535\n",
            "epoch 615/750   error=0.013459734081888575\n",
            "epoch 616/750   error=0.01339779942940641\n",
            "epoch 617/750   error=0.013336237275240323\n",
            "epoch 618/750   error=0.013275045885162392\n",
            "epoch 619/750   error=0.013214223516798605\n",
            "epoch 620/750   error=0.013153768419998251\n",
            "epoch 621/750   error=0.013093678837199207\n",
            "epoch 622/750   error=0.013033953003789253\n",
            "epoch 623/750   error=0.012974589148463288\n",
            "epoch 624/750   error=0.012915585493576288\n",
            "epoch 625/750   error=0.012856940255492161\n",
            "epoch 626/750   error=0.012798651644928216\n",
            "epoch 627/750   error=0.012740717867295494\n",
            "epoch 628/750   error=0.012683137123034555\n",
            "epoch 629/750   error=0.012625907607947118\n",
            "epoch 630/750   error=0.012569027513523068\n",
            "epoch 631/750   error=0.012512495027263159\n",
            "epoch 632/750   error=0.012456308332997266\n",
            "epoch 633/750   error=0.012400465611197986\n",
            "epoch 634/750   error=0.012344965039289951\n",
            "epoch 635/750   error=0.012289804791954436\n",
            "epoch 636/750   error=0.012234983041429476\n",
            "epoch 637/750   error=0.0121804979578054\n",
            "epoch 638/750   error=0.012126347709315853\n",
            "epoch 639/750   error=0.012072530462624183\n",
            "epoch 640/750   error=0.012019044383105191\n",
            "epoch 641/750   error=0.011965887635122404\n",
            "epoch 642/750   error=0.011913058382300657\n",
            "epoch 643/750   error=0.011860554787794107\n",
            "epoch 644/750   error=0.011808375014549653\n",
            "epoch 645/750   error=0.011756517225565793\n",
            "epoch 646/750   error=0.011704979584146784\n",
            "epoch 647/750   error=0.011653760254152412\n",
            "epoch 648/750   error=0.01160285740024302\n",
            "epoch 649/750   error=0.01155226918812006\n",
            "epoch 650/750   error=0.01150199378476208\n",
            "epoch 651/750   error=0.011452029358656244\n",
            "epoch 652/750   error=0.011402374080025219\n",
            "epoch 653/750   error=0.011353026121049683\n",
            "epoch 654/750   error=0.011303983656086303\n",
            "epoch 655/750   error=0.011255244861881291\n",
            "epoch 656/750   error=0.011206807917779487\n",
            "epoch 657/750   error=0.011158671005929096\n",
            "epoch 658/750   error=0.011110832311481987\n",
            "epoch 659/750   error=0.011063290022789699\n",
            "epoch 660/750   error=0.011016042331595047\n",
            "epoch 661/750   error=0.01096908743321954\n",
            "epoch 662/750   error=0.010922423526746439\n",
            "epoch 663/750   error=0.01087604881519958\n",
            "epoch 664/750   error=0.010829961505718144\n",
            "epoch 665/750   error=0.010784159809726994\n",
            "epoch 666/750   error=0.01073864194310321\n",
            "epoch 667/750   error=0.010693406126338208\n",
            "epoch 668/750   error=0.010648450584696077\n",
            "epoch 669/750   error=0.010603773548367636\n",
            "epoch 670/750   error=0.010559373252620775\n",
            "epoch 671/750   error=0.010515247937946583\n",
            "epoch 672/750   error=0.010471395850201811\n",
            "epoch 673/750   error=0.010427815240747302\n",
            "epoch 674/750   error=0.010384504366582666\n",
            "epoch 675/750   error=0.0103414614904772\n",
            "epoch 676/750   error=0.010298684881096974\n",
            "epoch 677/750   error=0.010256172813128368\n",
            "epoch 678/750   error=0.010213923567397795\n",
            "epoch 679/750   error=0.010171935430987942\n",
            "epoch 680/750   error=0.010130206697350336\n",
            "epoch 681/750   error=0.010088735666414533\n",
            "epoch 682/750   error=0.010047520644693674\n",
            "epoch 683/750   error=0.01000655994538672\n",
            "epoch 684/750   error=0.009965851888477276\n",
            "epoch 685/750   error=0.009925394800829034\n",
            "epoch 686/750   error=0.009885187016277996\n",
            "epoch 687/750   error=0.0098452268757214\n",
            "epoch 688/750   error=0.009805512727203435\n",
            "epoch 689/750   error=0.00976604292599789\n",
            "epoch 690/750   error=0.009726815834687551\n",
            "epoch 691/750   error=0.009687829823240719\n",
            "epoch 692/750   error=0.009649083269084546\n",
            "epoch 693/750   error=0.0096105745571755\n",
            "epoch 694/750   error=0.009572302080066934\n",
            "epoch 695/750   error=0.009534264237973678\n",
            "epoch 696/750   error=0.009496459438833916\n",
            "epoch 697/750   error=0.009458886098368207\n",
            "epoch 698/750   error=0.00942154264013587\n",
            "epoch 699/750   error=0.009384427495588526\n",
            "epoch 700/750   error=0.009347539104121193\n",
            "epoch 701/750   error=0.009310875913120653\n",
            "epoch 702/750   error=0.009274436378011315\n",
            "epoch 703/750   error=0.009238218962298601\n",
            "epoch 704/750   error=0.009202222137609838\n",
            "epoch 705/750   error=0.009166444383732788\n",
            "epoch 706/750   error=0.009130884188651791\n",
            "epoch 707/750   error=0.009095540048581574\n",
            "epoch 708/750   error=0.009060410467998825\n",
            "epoch 709/750   error=0.009025493959671504\n",
            "epoch 710/750   error=0.008990789044686016\n",
            "epoch 711/750   error=0.008956294252472186\n",
            "epoch 712/750   error=0.008922008120826181\n",
            "epoch 713/750   error=0.008887929195931397\n",
            "epoch 714/750   error=0.008854056032377261\n",
            "epoch 715/750   error=0.008820387193176137\n",
            "epoch 716/750   error=0.008786921249778302\n",
            "epoch 717/750   error=0.008753656782084956\n",
            "epoch 718/750   error=0.008720592378459537\n",
            "epoch 719/750   error=0.008687726635737098\n",
            "epoch 720/750   error=0.00865505815923199\n",
            "epoch 721/750   error=0.008622585562743836\n",
            "epoch 722/750   error=0.008590307468561773\n",
            "epoch 723/750   error=0.008558222507467106\n",
            "epoch 724/750   error=0.00852632931873432\n",
            "epoch 725/750   error=0.008494626550130568\n",
            "epoch 726/750   error=0.008463112857913607\n",
            "epoch 727/750   error=0.00843178690682823\n",
            "epoch 728/750   error=0.00840064737010128\n",
            "epoch 729/750   error=0.00836969292943526\n",
            "epoch 730/750   error=0.008338922275000507\n",
            "epoch 731/750   error=0.008308334105426075\n",
            "epoch 732/750   error=0.00827792712778928\n",
            "epoch 733/750   error=0.008247700057604038\n",
            "epoch 734/750   error=0.00821765161880782\n",
            "epoch 735/750   error=0.00818778054374758\n",
            "epoch 736/750   error=0.008158085573164362\n",
            "epoch 737/750   error=0.008128565456176875\n",
            "epoch 738/750   error=0.008099218950263902\n",
            "epoch 739/750   error=0.008070044821245629\n",
            "epoch 740/750   error=0.008041041843263975\n",
            "epoch 741/750   error=0.00801220879876186\n",
            "epoch 742/750   error=0.007983544478461533\n",
            "epoch 743/750   error=0.007955047681341903\n",
            "epoch 744/750   error=0.007926717214614977\n",
            "epoch 745/750   error=0.00789855189370142\n",
            "epoch 746/750   error=0.007870550542205184\n",
            "epoch 747/750   error=0.007842711991887337\n",
            "epoch 748/750   error=0.007815035082639105\n",
            "epoch 749/750   error=0.007787518662454096\n",
            "epoch 750/750   error=0.007760161587399761\n",
            "index: 0 predicted:[[0.86115052 0.11752196 0.15883226 0.01744185 0.00454383]] actual: [[1 0 0 0 0]] percent: [[86.11505229         inf         inf         inf         inf]]\n",
            "index: 1 predicted:[[0.0042656  0.05046202 0.11620799 0.93031925 0.02134891]] actual: [[0 0 0 1 0]] percent: [[        inf         inf         inf 93.03192474         inf]]\n",
            "index: 2 predicted:[[0.1301947  0.03213713 0.78356177 0.04418395 0.0489489 ]] actual: [[0 0 1 0 0]] percent: [[        inf         inf 78.35617729         inf         inf]]\n",
            "index: 3 predicted:[[0.01048941 0.06265848 0.10288526 0.02376471 0.92777181]] actual: [[0 0 0 0 1]] percent: [[        inf         inf         inf         inf 92.77718077]]\n",
            "index: 4 predicted:[[0.86115052 0.11752196 0.15883226 0.01744185 0.00454383]] actual: [[1 0 0 0 0]] percent: [[86.11505229         inf         inf         inf         inf]]\n",
            "index: 5 predicted:[[0.00686936 0.05441877 0.11808676 0.92288511 0.01623088]] actual: [[0 0 0 1 0]] percent: [[       inf        inf        inf 92.2885115        inf]]\n",
            "index: 6 predicted:[[0.08165438 0.85828713 0.04853921 0.04278595 0.03992852]] actual: [[0 1 0 0 0]] percent: [[        inf 85.82871346         inf         inf         inf]]\n",
            "index: 7 predicted:[[0.00854266 0.05417923 0.11026587 0.02566636 0.93186109]] actual: [[0 0 0 0 1]] percent: [[        inf         inf         inf         inf 93.18610932]]\n",
            "index: 8 predicted:[[0.08165438 0.85828713 0.04853921 0.04278595 0.03992852]] actual: [[0 1 0 0 0]] percent: [[        inf 85.82871346         inf         inf         inf]]\n",
            "index: 9 predicted:[[0.01048941 0.06265848 0.10288526 0.02376471 0.92777181]] actual: [[0 0 0 0 1]] percent: [[        inf         inf         inf         inf 92.77718077]]\n",
            "index: 10 predicted:[[0.0641323  0.04394183 0.77837266 0.05293783 0.06862941]] actual: [[0 0 1 0 0]] percent: [[        inf         inf 77.83726629         inf         inf]]\n",
            "index: 11 predicted:[[0.01334217 0.07203791 0.09733478 0.02186137 0.92127508]] actual: [[0 0 0 0 1]] percent: [[        inf         inf         inf         inf 92.12750764]]\n",
            "index: 12 predicted:[[0.06473299 0.86647004 0.04725594 0.04505606 0.04347009]] actual: [[0 1 0 0 0]] percent: [[        inf 86.64700372         inf         inf         inf]]\n",
            "index: 13 predicted:[[0.00686936 0.05441877 0.11808676 0.92288511 0.01623088]] actual: [[0 0 0 1 0]] percent: [[       inf        inf        inf 92.2885115        inf]]\n",
            "index: 14 predicted:[[0.86115052 0.11752196 0.15883226 0.01744185 0.00454383]] actual: [[1 0 0 0 0]] percent: [[86.11505229         inf         inf         inf         inf]]\n",
            "index: 15 predicted:[[0.06473299 0.86647004 0.04725594 0.04505606 0.04347009]] actual: [[0 1 0 0 0]] percent: [[        inf 86.64700372         inf         inf         inf]]\n",
            "index: 16 predicted:[[0.0042656  0.05046202 0.11620799 0.93031925 0.02134891]] actual: [[0 0 0 1 0]] percent: [[        inf         inf         inf 93.03192474         inf]]\n",
            "index: 17 predicted:[[0.06473299 0.86647004 0.04725594 0.04505606 0.04347009]] actual: [[0 1 0 0 0]] percent: [[        inf 86.64700372         inf         inf         inf]]\n",
            "index: 18 predicted:[[0.86115052 0.11752196 0.15883226 0.01744185 0.00454383]] actual: [[1 0 0 0 0]] percent: [[86.11505229         inf         inf         inf         inf]]\n",
            "index: 19 predicted:[[0.08165438 0.85828713 0.04853921 0.04278595 0.03992852]] actual: [[0 1 0 0 0]] percent: [[        inf 85.82871346         inf         inf         inf]]\n",
            "index: 20 predicted:[[0.01334217 0.07203791 0.09733478 0.02186137 0.92127508]] actual: [[0 0 0 0 1]] percent: [[        inf         inf         inf         inf 92.12750764]]\n",
            "index: 21 predicted:[[0.0042656  0.05046202 0.11620799 0.93031925 0.02134891]] actual: [[0 0 0 1 0]] percent: [[        inf         inf         inf 93.03192474         inf]]\n",
            "index: 22 predicted:[[0.1301947  0.03213713 0.78356177 0.04418395 0.0489489 ]] actual: [[0 0 1 0 0]] percent: [[        inf         inf 78.35617729         inf         inf]]\n",
            "index: 23 predicted:[[0.0042656  0.05046202 0.11620799 0.93031925 0.02134891]] actual: [[0 0 0 1 0]] percent: [[        inf         inf         inf 93.03192474         inf]]\n",
            "index: 24 predicted:[[0.92858823 0.03161686 0.16233597 0.00504783 0.06837573]] actual: [[1 0 0 0 0]] percent: [[92.85882348         inf         inf         inf         inf]]\n",
            "index: 25 predicted:[[0.01048941 0.06265848 0.10288526 0.02376471 0.92777181]] actual: [[0 0 0 0 1]] percent: [[        inf         inf         inf         inf 92.77718077]]\n",
            "index: 26 predicted:[[0.01334217 0.07203791 0.09733478 0.02186137 0.92127508]] actual: [[0 0 0 0 1]] percent: [[        inf         inf         inf         inf 92.12750764]]\n",
            "index: 27 predicted:[[0.92858823 0.03161686 0.16233597 0.00504783 0.06837573]] actual: [[1 0 0 0 0]] percent: [[92.85882348         inf         inf         inf         inf]]\n",
            "index: 28 predicted:[[0.86115052 0.11752196 0.15883226 0.01744185 0.00454383]] actual: [[1 0 0 0 0]] percent: [[86.11505229         inf         inf         inf         inf]]\n",
            "index: 29 predicted:[[0.0042656  0.05046202 0.11620799 0.93031925 0.02134891]] actual: [[0 0 0 1 0]] percent: [[        inf         inf         inf 93.03192474         inf]]\n",
            "index: 30 predicted:[[0.0641323  0.04394183 0.77837266 0.05293783 0.06862941]] actual: [[0 0 1 0 0]] percent: [[        inf         inf 77.83726629         inf         inf]]\n",
            "index: 31 predicted:[[0.86115052 0.11752196 0.15883226 0.01744185 0.00454383]] actual: [[1 0 0 0 0]] percent: [[86.11505229         inf         inf         inf         inf]]\n",
            "index: 32 predicted:[[0.0641323  0.04394183 0.77837266 0.05293783 0.06862941]] actual: [[0 0 1 0 0]] percent: [[        inf         inf 77.83726629         inf         inf]]\n",
            "index: 33 predicted:[[0.1301947  0.03213713 0.78356177 0.04418395 0.0489489 ]] actual: [[0 0 1 0 0]] percent: [[        inf         inf 78.35617729         inf         inf]]\n",
            "index: 34 predicted:[[0.08165438 0.85828713 0.04853921 0.04278595 0.03992852]] actual: [[0 1 0 0 0]] percent: [[        inf 85.82871346         inf         inf         inf]]\n",
            "index: 35 predicted:[[0.01048941 0.06265848 0.10288526 0.02376471 0.92777181]] actual: [[0 0 0 0 1]] percent: [[        inf         inf         inf         inf 92.77718077]]\n",
            "index: 36 predicted:[[0.0641323  0.04394183 0.77837266 0.05293783 0.06862941]] actual: [[0 0 1 0 0]] percent: [[        inf         inf 77.83726629         inf         inf]]\n",
            "index: 37 predicted:[[0.00686936 0.05441877 0.11808676 0.92288511 0.01623088]] actual: [[0 0 0 1 0]] percent: [[       inf        inf        inf 92.2885115        inf]]\n",
            "index: 38 predicted:[[0.1301947  0.03213713 0.78356177 0.04418395 0.0489489 ]] actual: [[0 0 1 0 0]] percent: [[        inf         inf 78.35617729         inf         inf]]\n",
            "index: 39 predicted:[[0.08165438 0.85828713 0.04853921 0.04278595 0.03992852]] actual: [[0 1 0 0 0]] percent: [[        inf 85.82871346         inf         inf         inf]]\n",
            "The Calculated Results of the training dataset are: [1, 4, 3, 5, 1, 4, 2, 5, 2, 5, 3, 5, 2, 4, 1, 2, 4, 2, 1, 2, 5, 4, 3, 4, 1, 5, 5, 1, 1, 4, 3, 1, 3, 3, 2, 5, 3, 4, 3, 2]\n",
            "======================TESTING DATA OUTPUT=============================\n",
            "The Predicted Results of the testing dataset are: [2, 1, 1, 4, 3, 2, 3, 5, 4]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:158: RuntimeWarning: divide by zero encountered in true_divide\n"
          ]
        }
      ]
    }
  ]
}